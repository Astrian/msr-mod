// utils/audioVisualizer.ts - å¹³è¡¡é¢‘è°±ç‰ˆæœ¬
import { ref, onUnmounted, Ref } from 'vue'

interface AudioVisualizerOptions {
  sensitivity?: number
  smoothing?: number
  barCount?: number
  debug?: boolean
  bassBoost?: number     // ä½éŸ³å¢å¼ºå€æ•° (é»˜è®¤ 0.7ï¼Œé™ä½ä½éŸ³)
  midBoost?: number      // ä¸­éŸ³å¢å¼ºå€æ•° (é»˜è®¤ 1.2)
  trebleBoost?: number   // é«˜éŸ³å¢å¼ºå€æ•° (é»˜è®¤ 1.5)
}

export function audioVisualizer(options: AudioVisualizerOptions = {}) {
  const {
    sensitivity = 1,
    smoothing = 0.7,
    barCount = 4,
    debug = false,
    bassBoost = 0.7,      // é™ä½ä½éŸ³æƒé‡
    midBoost = 1.2,       // æå‡ä¸­éŸ³
    trebleBoost = 1.5     // æå‡é«˜éŸ³
  } = options

  console.log('[AudioVisualizer] åˆå§‹åŒ–å¹³è¡¡é¢‘è°±ï¼Œé€‰é¡¹:', options)

  // å¯¼å‡ºçš„ç«–æ é«˜åº¦å€¼æ•°ç»„ (0-100)
  const barHeights: Ref<number[]> = ref(Array(barCount).fill(0))
  const isAnalyzing = ref(false)
  const error = ref<string | null>(null)
  const isInitialized = ref(false)

  // å†…éƒ¨å˜é‡
  let audioContext: AudioContext | null = null
  let analyser: AnalyserNode | null = null
  let source: MediaElementAudioSourceNode | null = null
  let dataArray: Uint8Array | null = null
  let animationId: number | null = null
  let currentAudioElement: HTMLAudioElement | null = null

  // è°ƒè¯•æ—¥å¿—
  function log(...args: any[]) {
    if (debug) {
      console.log('[AudioVisualizer]', ...args)
    }
  }

  // åˆå§‹åŒ–éŸ³é¢‘åˆ†æ
  function initAudioContext(audioElement: HTMLAudioElement) {
    if (!audioElement) {
      log('é”™è¯¯: éŸ³é¢‘å…ƒç´ ä¸ºç©º')
      return
    }
    
    if (audioContext) {
      log('AudioContext å·²å­˜åœ¨ï¼Œè·³è¿‡åˆå§‹åŒ–')
      return
    }

    try {
      log('å¼€å§‹åˆå§‹åŒ–éŸ³é¢‘ä¸Šä¸‹æ–‡...')

      audioContext = new (window.AudioContext || (window as any).webkitAudioContext)()
      log('AudioContext åˆ›å»ºæˆåŠŸ, çŠ¶æ€:', audioContext.state, 'é‡‡æ ·ç‡:', audioContext.sampleRate)

      // å¦‚æœä¸Šä¸‹æ–‡è¢«æš‚åœï¼Œå°è¯•æ¢å¤
      if (audioContext.state === 'suspended') {
        audioContext.resume().then(() => {
          log('AudioContext å·²æ¢å¤')
        })
      }

      analyser = audioContext.createAnalyser()
      
      // å°è¯•åˆ›å»ºéŸ³é¢‘æº
      try {
        source = audioContext.createMediaElementSource(audioElement)
        log('MediaElementSource åˆ›å»ºæˆåŠŸ')
      } catch (sourceError) {
        log('åˆ›å»º MediaElementSource å¤±è´¥:', sourceError)
        error.value = 'CORS é”™è¯¯: æ— æ³•è®¿é—®è·¨åŸŸéŸ³é¢‘'
        return
      }
      
      // ä¼˜åŒ–åˆ†æå™¨é…ç½®
      analyser.fftSize = 2048        // å¢åŠ åˆ†è¾¨ç‡
      analyser.smoothingTimeConstant = smoothing
      analyser.minDecibels = -100    // æ›´ä½çš„æœ€å°åˆ†è´
      analyser.maxDecibels = -30     // è°ƒæ•´æœ€å¤§åˆ†è´èŒƒå›´
      
      log('åˆ†æå™¨é…ç½®:', {
        fftSize: analyser.fftSize,
        frequencyBinCount: analyser.frequencyBinCount,
        sampleRate: audioContext.sampleRate,
        frequencyResolution: audioContext.sampleRate / analyser.fftSize
      })
      
      // è¿æ¥éŸ³é¢‘èŠ‚ç‚¹
      source.connect(analyser)
      analyser.connect(audioContext.destination)
      
      // åˆ›å»ºæ•°æ®æ•°ç»„
      dataArray = new Uint8Array(analyser.frequencyBinCount)
      
      isInitialized.value = true
      error.value = null
      log('âœ… éŸ³é¢‘å¯è§†åŒ–å™¨åˆå§‹åŒ–æˆåŠŸ')
      
    } catch (err) {
      log('âŒ éŸ³é¢‘ä¸Šä¸‹æ–‡åˆå§‹åŒ–å¤±è´¥:', err)
      error.value = `åˆå§‹åŒ–å¤±è´¥: ${err instanceof Error ? err.message : String(err)}`
      isInitialized.value = false
    }
  }

  // å¼€å§‹åˆ†æ
  function startAnalysis() {
    if (!analyser || !dataArray || !isInitialized.value) {
      log('âŒ æ— æ³•å¼€å§‹åˆ†æ: åˆ†æå™¨æœªåˆå§‹åŒ–')
      return
    }
    
    log('âœ… å¼€å§‹é¢‘è°±åˆ†æ')
    isAnalyzing.value = true
    animate()
  }

  // åœæ­¢åˆ†æ
  function stopAnalysis() {
    log('åœæ­¢é¢‘è°±åˆ†æ')
    isAnalyzing.value = false
    if (animationId) {
      cancelAnimationFrame(animationId)
      animationId = null
    }
    barHeights.value = Array(barCount).fill(0)
  }

  // åŠ¨ç”»å¾ªç¯
  function animate() {
    if (!isAnalyzing.value || !analyser || !dataArray || !audioContext) return
    
    // è·å–é¢‘ç‡æ•°æ®
    analyser.getByteFrequencyData(dataArray)
    
    // ä½¿ç”¨å¹³è¡¡çš„é¢‘æ®µåˆ†å‰²
    const frequencyBands = divideFrequencyBandsBalanced(dataArray, barCount, audioContext.sampleRate)
    
    // åº”ç”¨é¢‘æ®µç‰¹å®šçš„å¢å¼º
    const enhancedBands = applyFrequencyEnhancement(frequencyBands)
    
    // æ›´æ–°ç«–æ é«˜åº¦ (0-100)
    barHeights.value = enhancedBands.map(value => 
      Math.min(100, Math.max(0, (value / 255) * 100 * sensitivity))
    )
    
    animationId = requestAnimationFrame(animate)
  }

  // å¹³è¡¡çš„é¢‘æ®µåˆ†å‰² - ä½¿ç”¨å¯¹æ•°åˆ†å¸ƒå’Œäººè€³æ„ŸçŸ¥ç‰¹æ€§
  function divideFrequencyBandsBalanced(data: Uint8Array, bands: number, sampleRate: number): number[] {
    const nyquist = sampleRate / 2
    const result: number[] = []
    
    // å®šä¹‰äººè€³æ„ŸçŸ¥çš„é¢‘ç‡èŒƒå›´ (Hz)
    const frequencyRanges = [
      { min: 20, max: 250, name: 'ä½éŸ³' },      // ä½éŸ³
      { min: 250, max: 2000, name: 'ä¸­ä½éŸ³' },   // ä¸­ä½éŸ³  
      { min: 2000, max: 8000, name: 'ä¸­é«˜éŸ³' },  // ä¸­é«˜éŸ³
      { min: 8000, max: 20000, name: 'é«˜éŸ³' }   // é«˜éŸ³
    ]
    
    for (let i = 0; i < bands; i++) {
      const range = frequencyRanges[i] || frequencyRanges[frequencyRanges.length - 1]
      
      // å°†é¢‘ç‡è½¬æ¢ä¸º bin ç´¢å¼•
      const startBin = Math.floor((range.min / nyquist) * data.length)
      const endBin = Math.floor((range.max / nyquist) * data.length)
      
      // ç¡®ä¿èŒƒå›´æœ‰æ•ˆ
      const actualStart = Math.max(0, startBin)
      const actualEnd = Math.min(data.length - 1, endBin)
      
      if (debug && Math.random() < 0.01) {
        log(`é¢‘æ®µ ${i} (${range.name}): ${range.min}-${range.max}Hz, bins ${actualStart}-${actualEnd}`)
      }
      
      // è®¡ç®—è¯¥é¢‘æ®µçš„ RMS (å‡æ–¹æ ¹) å€¼ï¼Œè€Œä¸æ˜¯ç®€å•å¹³å‡
      let sumSquares = 0
      let count = 0
      
      for (let j = actualStart; j <= actualEnd; j++) {
        const value = data[j]
        sumSquares += value * value
        count++
      }
      
      const rms = count > 0 ? Math.sqrt(sumSquares / count) : 0
      result.push(rms)
    }
    
    return result
  }

  // åº”ç”¨é¢‘æ®µç‰¹å®šçš„å¢å¼º
  function applyFrequencyEnhancement(bands: number[]): number[] {
    const boosts = [bassBoost, midBoost, trebleBoost, trebleBoost]
    
    return bands.map((value, index) => {
      const boost = boosts[index] || 1
      let enhanced = value * boost
      
      // åº”ç”¨å‹ç¼©æ›²çº¿ï¼Œé˜²æ­¢è¿‡åº¦å¢å¼º
      enhanced = 255 * Math.tanh(enhanced / 255)
      
      return Math.min(255, Math.max(0, enhanced))
    })
  }

  // è¿æ¥éŸ³é¢‘å…ƒç´ 
  function connectAudio(audioElement: HTMLAudioElement) {
    log('ğŸ”— è¿æ¥éŸ³é¢‘å…ƒç´ ...')
    
    if (currentAudioElement === audioElement) {
      log('éŸ³é¢‘å…ƒç´ ç›¸åŒï¼Œè·³è¿‡é‡å¤è¿æ¥')
      return
    }
    
    // æ¸…ç†æ—§çš„è¿æ¥
    cleanup()
    
    currentAudioElement = audioElement
    
    // ç­‰å¾…éŸ³é¢‘åŠ è½½å®Œæˆåå†åˆå§‹åŒ–
    if (audioElement.readyState >= 2) {
      initAudioContext(audioElement)
    } else {
      audioElement.addEventListener('loadeddata', () => {
        initAudioContext(audioElement)
      }, { once: true })
    }
    
    // ç›‘å¬æ’­æ”¾çŠ¶æ€
    audioElement.addEventListener('play', startAnalysis)
    audioElement.addEventListener('pause', stopAnalysis)
    audioElement.addEventListener('ended', stopAnalysis)
    
    // ç›‘å¬é”™è¯¯
    audioElement.addEventListener('error', (e) => {
      log('âŒ éŸ³é¢‘åŠ è½½é”™è¯¯:', e)
      error.value = 'éŸ³é¢‘åŠ è½½å¤±è´¥'
    })
  }

  // æ–­å¼€éŸ³é¢‘å…ƒç´ 
  function disconnectAudio() {
    if (currentAudioElement) {
      currentAudioElement.removeEventListener('play', startAnalysis)
      currentAudioElement.removeEventListener('pause', stopAnalysis)
      currentAudioElement.removeEventListener('ended', stopAnalysis)
      currentAudioElement = null
    }
    cleanup()
  }

  // æ¸…ç†èµ„æº
  function cleanup() {
    stopAnalysis()
    if (audioContext && audioContext.state !== 'closed') {
      audioContext.close()
    }
    audioContext = null
    analyser = null
    source = null
    dataArray = null
    isInitialized.value = false
  }

  // æ‰‹åŠ¨æµ‹è¯•æ•°æ®
  function testWithFakeData() {
    log('ğŸ§ª å¼€å§‹å¹³è¡¡é¢‘è°±æ¨¡æ‹Ÿæµ‹è¯•')
    isAnalyzing.value = true
    
    let testCount = 0
    const maxTests = 50
    
    const fakeInterval = setInterval(() => {
      // æ¨¡æ‹Ÿæ›´å¹³è¡¡çš„é¢‘è°±æ•°æ®
      barHeights.value = [
        Math.random() * 60 + 20,  // ä½éŸ³ï¼š20-80
        Math.random() * 80 + 10,  // ä¸­ä½éŸ³ï¼š10-90
        Math.random() * 90 + 5,   // ä¸­é«˜éŸ³ï¼š5-95
        Math.random() * 70 + 15   // é«˜éŸ³ï¼š15-85
      ]
      testCount++
      
      if (testCount >= maxTests) {
        clearInterval(fakeInterval)
        barHeights.value = Array(barCount).fill(0)
        isAnalyzing.value = false
        log('ğŸ§ª æ¨¡æ‹Ÿæµ‹è¯•ç»“æŸ')
      }
    }, 100)
  }

  // åŠ¨æ€è°ƒæ•´å¢å¼ºå‚æ•°
  function updateEnhancement(bass: number, mid: number, treble: number) {
    options.bassBoost = bass
    options.midBoost = mid
    options.trebleBoost = treble
    log('æ›´æ–°é¢‘æ®µå¢å¼º:', { bass, mid, treble })
  }

  // ç»„ä»¶å¸è½½æ—¶æ¸…ç†
  onUnmounted(() => {
    disconnectAudio()
  })

  return {
    barHeights,
    isAnalyzing,
    isInitialized,
    error,
    connectAudio,
    disconnectAudio,
    startAnalysis,
    stopAnalysis,
    testWithFakeData,
    updateEnhancement
  }
}